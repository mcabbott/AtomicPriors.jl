
using Random

"""
    mcarlo(Î , Ïƒ, [n])

Calculates mutual information `I(X;Î˜)` for gaussian noise, by monte carlo sampling
roughly `n` times. Really `cld(n,k)` per atom, i.e. `cld(n,k)*k` in total.
(Default is `2k` points in total, and at least 1000.)

As usual positions of prior's delta functions are the `k` columns of `Î `
and data is `x ~ ð’©(Î¸,ÏƒÂ²)` in `d` dimensions, `d,k=size(Î )`.

Keyword `threads=true` runs multi-threaded, default is `Threads.nthreads()>1`.

Compare to `mutual(X,Î ,Ïƒ)` with explicit grid, and `mkern(Î , Ïƒ)` KDE very-approx.
"""
mcarlo(Î ::Weighted, Ïƒ::Real, n::Int=max(2*size(Î ,2),1000); kw...) = mcarlo(array(Î ), weights(Î ), Ïƒ, n; kw...)

function mcarlo(theta::Matrix{T1}, weights::Vector{T2}, sigma::Real, iter::Int; threads::Bool=Threads.nthreads()>1) where {T1,T2}
    T = promote_type(T1,T2)
    eltype(weights) == T || return mcarlo(theta, map(T,weights), sigma, iter)
    sigma isa T || return mcarlo(theta, weights, T(sigma), iter)

    d,k = size(theta)
    @assert length(weights) == k
    if k==0
        @warn "mcarlo run with zero points, returning 0"
        return 0.0
    elseif iter<k
        @warn "ignoring n = $iter as this is smaller than k = $k"
    elseif sigma>Ï€ && sigma isa Int
        @warn "mcarlo called with integer Ïƒ = $sigma, is that what you wanted? (And n = $iter iterations)"
    end

    threads && return mcarlo_threads(theta, weights, sigma, iter)

    sumlog = zero(T)      # accumulate almost the answer
    randx = zeros(T,d)    # pre-allocate for random x
    mi2v = 1/(-2*sigma^2) # quiker to work this out once

    iterper = cld(iter, k) # unlike div this gives 1 if iter<k
    for a=1:k             # iterate over cols with nonzero weight
        weights[a] < MINWEIGHT && continue
        @inbounds for loop = 1:iterper
            # first draw data point x
            for r=1:d
                randx[r] = theta[r,a] + sigma * randn(T)
            end
            # contribution Î»_a log( p(x|Î¸_a) / p(x) )
            sumlog += weights[a] * log_pxÎ¸a_px(randx, a, theta, weights, d,k, mi2v)
        end
    end
    sumlog / iterper
end

@inline function log_pxÎ¸a_px(randx, a, theta, weights, d,k, mi2v)
    T = eltype(weights)
    px = zero(T)
    pxÎ¸a = zero(T)
    # build up p(x), and get p(x|Î¸_a) along the way.
    @inbounds for j=1:k
        dist2 = zero(T)
        for r=1:d
            dist2 += (randx[r] - theta[r,j])^2
        end
        Pj = exp(dist2 * mi2v) # prefactor of gaussian would cancel in pxÎ¸a/px
        if j == a
            pxÎ¸a = Pj
        end
        px += Pj * weights[j]
    end
    log(pxÎ¸a / px)
end

function mcarlo_threads(theta::Matrix, weights::Vector{T}, sigma::Real, iter::Int) where {T}
    d,k=size(theta)
    # @assert length(weights)==k # removing this cures type-instability WTF?
    mi2v = (1/(-2*sigma^2))

    caches = [zeros(T,d) for tid=1:Threads.nthreads()]   # working space per thread
    sumlog = zeros(T, Threads.nthreads())   # accumulate per thread, no locks, total at end
    # generators = [MersenneTwister() for tid=1:Threads.nthreads()]

    iterper = cld(iter, k)
    Threads.@threads for a=1:k
        weights[a] < MINWEIGHT && continue

        tid = Threads.threadid()
        # rng = generators[tid]
        randx = caches[tid]

        @inbounds for loop = 1:iterper
            for r=1:d
                randx[r] = theta[r,a] + sigma * randn(T) # (rng)
            end
            sumlog[tid] += weights[a] * log_pxÎ¸a_px(randx, a, theta, weights, d,k, mi2v)
        end
    end
    sum(sumlog) / iterper
end

# On Julia 1.3 the default rng is thread-safe.
# If it's a bottleneck you can look at faster ones:
# https://github.com/JuliaLang/julia/issues/27614
# https://sunoru.github.io/RandomNumbers.jl/dev/man/benchmark/#Speed-Test-1

# RI2 had gradient definitions for mcarlo(), but not so useful really.

"""
    fcarlo(Ï†, Î , Ïƒ, [n]) -> real
    fcarlo(Î¦, Î , Ïƒ, [n]) -> vector

Calculates bayes risk `f_KL(Ï†)` for gaussian noise, by monte carlo sampling
roughly `n` times in total (default is `2k` points in total, and at least 1000).

To apply to many points `Ï†1,Ï†2,...` at once, give a many-colum `Î¦::Weighted`, and get a vector.

Similar to `fbayes(Î¦,X,Î ,Ïƒ)` with explicit grid, and `fkern(Î¦,Î ,Ïƒ)` KDE approx.

    fcarlo(f, Î¦, Î , Ïƒ) = fcarlo(f(Î¦), f(Î ), Ïƒ)
    fcarlo(Î , Ïƒ) = fcarlo(Î , Î , Ïƒ)

Given a function, it applies this to both `Î¦` and `Î `.
If not given `Î¦`, then it uses `Î ` for this too.
"""
fcarlo(phi::AbsVec, prior::Weighted, sigma::Real, n::Int=max(1000, 2*size(prior,2))) =
    fcarlo(reshape(phi,:,1), array(prior), weights(prior), sigma, n) |> first

fcarlo(manyphi::Weighted, prior::Weighted, sigma::Real, n::Int=max(1000, 2*size(prior,2))) =
    fcarlo(array(manyphi), array(prior), weights(prior), sigma, n)

# with a function
fcarlo(f, phi::AbsVec, prior::Weighted, Ïƒ::Real, n::Int...) = fcarlo(f(WeightedMatrix(phi)), f(prior), Ïƒ, n...) |> first
fcarlo(f, phis::Weighted, prior::Weighted, Ïƒ::Real, n::Int...) = fcarlo(f(phis), f(prior), Ïƒ, n...)

# without phi
fcarlo(prior::Weighted, Ïƒ::Real, n::Int...) = fcarlo(prior, prior, Ïƒ, n...)
fcarlo(f, prior::Weighted, Ïƒ::Real, n::Int...) = fcarlo(f, prior, prior, Ïƒ, n...)

function fcarlo(phi::AbstractMatrix{T1}, theta::AbstractMatrix{T2}, weights::Vector{T3}, sigma::Real, iter::Int) where {T1,T2,T3}
    T = promote_type(T1, T2, T3, typeof(sigma))
    eltype(phi) == T || return fcarlo(map(T,phi), theta, weights, sigma, iter)
    eltype(theta) == T || return fcarlo(phi, map(T,theta), weights, sigma, iter)
    eltype(weights) == T || return fcarlo(phi, theta, map(T,weights), sigma, iter)
    sigma isa T || return fcarlo(phi, theta, weights, T(sigma), iter)

    d, k = size(theta)
    dÏ•, kÏ• = size(phi)
    iter<k && @warn "ignoring n = $iter as this is smaller than k = $k"
    @assert length(weights) == k
    dÏ•==d || error("dimension of point Ï• must match that of prior Î¸")

    out = zeros(T,kÏ•)

    randx = zeros(T,d)
    mi2v = 1/(-2*sigma^2)

    iterper = cld(iter, kÏ•)
    for b=1:kÏ•
        @inbounds for loop = 1:iterper
            # draw data point x
            for r=1:d
                randx[r] = phi[r,b] + sigma * randn(T)
            end
            # save log( p(x|Ï•_b) / p(x) ) -- different inner function this time
            out[b] += log_pxÏ•b_px(randx, b,phi, theta, weights, d,k, mi2v) / iterper
        end
    end
    out
end

@inline function log_pxÏ•b_px(randx, b,phi, theta, weights, d,k, mi2v)
    T = eltype(weights)
    #  build up p(x)
    px = zero(T)
    @inbounds for j=1:k
        dist2 = zero(T)
        for r=1:d
            dist2 += (randx[r] - theta[r,j])^2
        end
        Pj = exp(dist2 * mi2v) # prefactor of gaussian would cancel
        px += Pj * weights[j]
    end
    # need p(x|Ï•b) separately as Ï•b not among the list
    dist2â€² = zero(T)
    for r=1:d
        dist2â€² += (randx[r] - phi[r,b])^2
    end
    pxÏ•b = exp(dist2â€² * mi2v)
    # log(pxÏ•b / px) # |> finite # seems dodgy
    safelogpoq(pxÏ•b, px)
end

function safelogpoq(p,q)
    x = log(p/q)
    ifelse(iszero(p), zero(x), x)
end
